---
title: "Does Humor Impact  Dating Success?"
Team member: "Brian Xiao, Erin Reed, KT Norton, Luka Liu and Quazi Fairooz"
date: "12/11/2023"
output: 
  pdf_document: 
    number_sections: true
---

```{r package loads, include=FALSE, warning=FALSE}
# install.packages("pwr") need to install if you don't have it yet
library(pwr)
library(data.table)
library(sandwich)
library(lmtest)

library(ggplot2)
library(knitr)
library(stargazer)
```

# Abstract
This study investigates the user personalities displayed on dating app profiles and their subsequent engagement levels. By comparing the effects of creating a neutral personality profile with crafting a highly humorous and intriguing personality description, we aim to examine the impact of varying personality portrayals in dating app profiles (independent of accompanying photos) on user interactions and engagement. Our experiment generated the following results: dating profiles with humorous textual cues received XX as many likes and XX matches. XXX statistically significant. We suspect primary factors like photographs and demographic backgrounds have a greater influence on first impressions (views) rather than dating pursuits (matches). These results can be beneficial for online dating app users as they evaluate where to spend most of their time when they develop their dating profiles.

# Introducation
Humor is a universal human experience that promotes bonding and positive social interaction. Historically, humor has been shown to decrease social tension and increase likability. The treatment involving the use of humor in the description is expected to change the measured behavior of humans who receive it. In the context of dating, where first impressions are critical, a humorous profile may pique interest by presenting someone as relatable, fun, and approachable, thereby increasing the chances of having dating success. 

Our team is interested in investigating whether humorous expressions through textual cues affect dating success on a dating app. Current academic literature has evaluated this concept in similar, yet different, ways. First, a research study has evaluated how messages with different levels of humor impact a person’s perceived attractiveness (Garove and Farley, 2015). Second, a research study evaluated how live humor and laughter in discourse are associated with perceived attractiveness (Hall, 2015). Lastly, a few research studies have evaluated attractiveness (Fiore et all, 2008) or first impressions (Zanden, 2021) specifically within dating apps. However, none of these research studies evaluate whether humorous textual cues within a dating app affect a person’s attractiveness when primary cues like photographs and demographic information remain constant.

# Experiment Concept
People spend hours daily on dating apps looking for potential partners. The selection process gets more complicated with the increase in the abundance of options available to them. While the superficial qualities and end goals are highly esteemed,  a profile with a humorous caption tends to stand out among the numerous mundane ones as it indicates a witty personality, something which is not easily captured through just pictures and usual descriptions. 

Our intervention variable is textual differences between the two Hinge dating profiles. Our subjects will experience a dating profile that is humorous and fun (treatment) and a dating profile that is plain and unimaginative (control). To reduce noise driven by confounding variables, we plan to ensure both profiles have the same characteristics and content apart from responses to question prompts. Controlling for these other factors is an important feature of this experience because while studies have shown that photos and demographics heavily influence dating profile experiences, this experiment is meant to focus on the causal effect personality traits expressed through text can have on someone's dating success on Hinge.

Due to limitations in timing and resources, we are utilizing only the Hinge application, but if we could replicate the results on other dating apps such as Tinder or Bumble, we hope to see similar results.

# Experiment Design
The objective of this experiment is to explore the impact of incorporating a humorous personality into dating app profiles on user engagement. Specifically, we will compare the effects of creating a neutral personality profile with crafting a highly humorous and intriguing personality description on user interactions and engagement. We target the participants to be a diverse group of participants aged 18-25. Participants’ profile photos will be the same to ensure that the study focuses solely on the impact of the humorous personality. Each of our team members will create fake profiles for both control and treatment groups based on the same photo. In the control group, the profile will be created as a neutral personality profile while in the treatment group, the profile will be created as a highly humorous and intriguing personality in the description. The fake profile will launch at the same time on the dating app for a specified period of time(e.g. 4-6 weeks). The number of likes and matches will be the key metric we are going to measure. 

We have chosen two locations in the United States— New York City and San Francisco to introduce the fictitious dating profiles. The underlying assumption is that users of the dating app from these two U.S. locations will exhibit similar reactions regardless of whether a humorous personality is presented or not. Our intention is to keep other demographic differences to a minimum to strengthen this assumption. Moreover, to prevent a single participant from encountering two identical profiles simultaneously, we have made the deliberate decision to launch identical profiles in different locations. For instance, one profile (the control group) will be launched in San Francisco, while the other profile (the treatment group) will be launched in Los Angeles. This collection of data will serve as a foundational reference point, aiding us in ensuring that the two groups—those exposed to a neutral personality profile and those exposed to a humorous personality description—are comparable in terms of their demographic characteristics. It also safeguards against the possibility of a single individual viewing both profiles concurrently.

Since the control/treatment profile will be launched at the same time, the engagement metrics, such as the number of matches, likes, and comments will be zero as a baseline. The following variables are measured after the treatment (ie. activating the fake profile) to assess the impact on user engagement. 

Number of profile likes: How many users have liked the profile
Number of comments: How many users have commented on the profile
Number of matches: How many users have matched with the profile

Dating apps necessitate mutual likes for a match to occur, for example, if one profile swipes right on five people, their maximum potential matches will be limited to five. We will standardize the maximum number of matches each profile can receive after the treatment. This will ensure that our created profile’s actions (how much time we swipe right) do not unduly influence the effectiveness of our measures.

Through these variables both before and after administering the treatment, we can assess how the humor personality influenced user engagement on dating apps.

Due to the nature of this experiment creating fake dating profiles for our sample, our team will make up the participants of this experiment. Each team member will create 2 (or 4) dating profiles - one for control and one for treatment. These profiles will be identical in everything except for the profile question prompts, which will be neutral in control and humorous in treatment.

# Power Analysis

Our study utilized samples drawn from five distinct account profiles, each created by individual team members. Each team member generated two account profiles featuring the same photo: one with a factual description (control) and another with a humorous description (treatment). The team members, on a daily basis, swiped right on 10 candidates using the app and recorded the number of matches as our treatment effect. Consequently, our daily samples consisted of 10 profiles in the control group and 10 profiles in the treatment group, summing up to 10 * 5 profiles for each category.

Building upon prior research outlined in the study titled "Exploring the influences of profile perceptions and different pick-up lines on dating outcomes on Tinder: An online experiment" (Journal of Social Psychology, 32(4), 123-145, https://doi.org/10.1016/j.chb.2020.106667), it has been determined that the use of humor and complimentary messages significantly predicts success for men in the realm of online dating. This body of research indicates that incorporating humor into the dating profiles of men is likely to result in a higher number of matches compared to profiles lacking humor. Moreover, the findings suggest a treatment effect of a 17% increase, as measured on a 7-point Likert-type scale. In the forthcoming experiment, our expectation is to observe a positive impact from the treatment, aiming to anticipate a range of 17% to 20% treatment effect compared to the control group.

## To simulate a power analysis based on treatment effect 
The provided code and plot are derived from simulating various treatment effect sizes, ranging from 5% to 100% with a 5% incremental increase, while aiming to achieve a consistent power level of 0.8. This illustrates how the necessary sample size changes with varying treatment effect sizes.

```{r}

# Set parameters
alpha <- 0.05           # Significance level
power <- 0.8            # Desired power
treatment_effect_sizes <- seq(0.05, 1, by = 0.05)  # Range of treatment effect sizes


# Initialize variables
target_sample_size <- NA
target_effect_size <- NA

# Function to calculate power for a given effect size and sample size
calculate_power <- function(effect_size, sample_size) {
  pwr.t.test(d = effect_size, n = sample_size, sig.level = alpha, type = "two.sample")$power
}

# Iterate through treatment effect sizes and find the combination that achieves the desired power
for (effect_size in treatment_effect_sizes) {
  # Use a range of sample sizes for exploration
  for (sample_size in seq(10, 500, by = 10)) {
    current_power <- calculate_power(effect_size, sample_size)
    
    if (current_power >= power) {
      target_sample_size <- sample_size
      target_effect_size <- effect_size
      break
    }
  }
  
  if (!is.na(target_sample_size)) {
    break
  }
}

# Function to calculate sample size for a given treatment effect size
calculate_sample_size <- function(effect_size, alpha, power) {
  pwr.t.test(d = effect_size, sig.level = alpha, power = power, type = "two.sample")$n
}

# Calculate sample sizes for each treatment effect size
sample_sizes <- sapply(treatment_effect_sizes, calculate_sample_size, alpha = alpha, power = power)

# Plot the results
plot(sample_sizes, treatment_effect_sizes, type = "l", col = "blue",
     xlab = "Sample Size", ylab = "Treatment Effect Size",
     main = "Power Analysis based on treatment effect")

# Add a horizontal line for the desired power
abline(h = target_effect_size, col = "red", lty = 2)
abline(v = target_sample_size, col = "orange", lty = 2)

# Add legend
legend("topright", legend = c("Target Effect Size", "Target Sample Size"), 
       col = c("red", "orange"), lty = c(2, 1))


```
```{r, include=FALSE}
# Print the results
cat("Desired Power:", power, "\n")
cat("Target Sample Size:", target_sample_size, "\n")
cat("Target Treatment Effect Size:", target_effect_size, "\n")

```

### Summary on power analysis based on treatment effect 
As demonstrated in the graph above, a smaller effect size typically requires a larger sample size to achieve the same level of statistical power. Conversely, a larger effect size can be detected with a smaller sample size. According to the analysis, in order to ensure a high probability (80%) of detecting a treatment effect of 20% (In this case, a treatment effect of 20% suggests that the study is designed to detect a 20% difference between groups, which could be a treatment group and a control group), a sample size of 400 is recommended for the statistical test being conducted. 


## To simulate a power analysis based on data dispersion 

The presented code and plot result from simulating different levels of dispersion (standard deviation) ranging from 0.05 to 2, with a 5% incremental increase. The goal is to maintain a consistent power level of 0.8. In this simulation, we have assumed an Average Treatment Effect (ATE) of 20%, as suggested in a prior simulation. This demonstrates the increasing required sample size as the standard deviation dispersion becomes higher.

```{r}

# Install and load the necessary library

# Set parameters
alpha <- 0.05           # Significance level
power <- 0.8            # Desired power
mean1 <- 0.5            # Mean of group 1(control)
mean2 <- 0.7           # Mean of group 2(humor)
std_devs <- seq(0.05, 2, by = 0.05)  # Range of standard deviations to explore

# Initialize variables
target_sample_size <- NA
target_std_dev <- NA

# Function to calculate power for a given standard deviation and sample size
calculate_power <- function(std_dev, sample_size) {
  d <- (mean2 - mean1) / std_dev  # Cohen's d effect size
  pwr.t.test(d = d, n = sample_size, sig.level = alpha, type = "two.sample")$power
}

# Iterate through standard deviations and find the combination that achieves the desired power
for (std_dev in std_devs) {
  # Use a range of sample sizes for exploration
  for (sample_size in seq(10, 500, by = 10)) {
    current_power <- calculate_power(std_dev, sample_size)
    
    if (current_power >= power) {
      target_sample_size <- sample_size
      target_std_dev <- std_dev
      break
    }
  }
  
  if (!is.na(target_sample_size)) {
    break
  }
}
# Function to calculate sample size for a given standard deviation
calculate_sample_size <- function(std_dev, alpha, power) {
  d <- (mean2 - mean1) / std_dev  # Cohen's d effect size
  pwr.t.test(d = d, sig.level = alpha, power = power, type = "two.sample")$n
}

# Calculate sample sizes for each standard deviation
sample_sizes <- sapply(std_devs, calculate_sample_size, alpha = alpha, power = power)

# Plot the results
plot(sample_sizes, std_devs, type = "l", col = "blue",
     xlab = "Sample Size", ylab = "Standard Deviations",
     main = "Power Analysis based on Standard Deviation")

# Add a horizontal line for the desired power
abline(v = 400, col = "orange", lty = 2)

# Add legend
legend("topright", legend = c("Target Sample Size"), 
       col = c("orange"), lty = c(2, 1))

```

### Summary on power analysis based on data dispersion 
Standard deviation is a measure of the spread or dispersion of data. A larger standard deviation suggests more variability in the data. To increase the chances of detecting a true effect in the presence of higher variability, a larger sample size is needed. This is because a larger sample size provides more information and helps to better estimate the underlying population parameters. Therefore, as the  standard deviation (dispersion) becomes higher, it becomes more challenging to detect smaller effects, and a larger sample size is required to achieve the desired level of statistical power.

## To simulate a power analysis based on sample size

The presented code and plot result from simulating different sample sizes ranging from 10 to 500, with 10 unit incremental increase. The goal is to reach a power level of 0.8. In this simulation, we have assumed an Average Treatment Effect (ATE) of 20% and a Standard Deviation of 1.0, as suggested in a prior simulation. This demonstrates the increasing required sample size to reach a power level of 0.8 or higher.

```{r}
# Install and load the necessary library

# Set parameters
alpha <- 0.05           # Significance level
mean1 <- 0.5            # Mean of group 1(control)
mean2 <- 0.7           # Mean of group 2(humor)
std_dev <- 1.0        #standard deviation
sample_size <- seq(100, 500, by = 10) # Range of sample sizes to explore

# Initialize variables
power <- NA

# Function to calculate power for a given standard deviation and sample size
calculate_power <- function(std_dev, sample_size, alpha) {
  d <- (mean2 - mean1) / std_dev  # Cohen's d effect size
  pwr.t.test(d = d, n = sample_size, sig.level = alpha, type = "two.sample")$power
}

# For loop to calculate power for a given sample size

for(i in 1:length(sample_size)) { 
  power[i] <- calculate_power(std_dev, sample_size[i],alpha)
}


# Plot the results
plot(sample_size, power, type = "l", col = "blue",
     xlab = "Sample Size", ylab = "Power",
     main = "Power Analysis based on Sample Size")

# Add a horizontal line for the desired power
abline(h = .80, col = "orange", lty = 2)

# Add legend
legend("bottomright", legend = c("Target Power"), 
       col = c("orange"), lty = c(2, 1))


```
### Summary on power analysis based on sample size 
Sample size is a measure of the quantity of experiment data available. A larger sample size suggests higher power when standard deviation and average treatment effect are constant. To increase the chances of detecting a true effect when standard deviation is 1 and average treatment effect is 20%, a larger sample size is needed. This is because a larger sample size provides more information and helps to better estimate the underlying population parameters. Therefore, if the sample size is too small, it becomes more challenging to detect a true effect. A 400 sample size is required to achieve the desired level of statistical power (0.80) when standard deviation and average treatment effect are held constant.

In summary, our power analysis suggests that a sample size of 400 is appropriate for our experiment, providing a good balance between statistical power and practical feasibility. This conclusion informs the planning and execution of our study, setting expectations for the likelihood of detecting the 20% treatment effect.

# Data Cleaning
The following data captures the three major metrics such as swipes, likes, matches, and comments for different profiles on specific dates, categorized into control and treatment groups. The data consist of  information related to user profiles on a dating app. Here is a summary of the data columns:

- Owner: The team member who owns the profile.
- Profile_Name: The name associated with the profile.
- City: The city where the profile is located.
- Treat: Indicates whether the profile is in the control group or the treatment group.
- Treat_binary: Logical condition into binary values (0 for "Control" and 1 for "Treatment").
- Date: The date of the recorded data.
- Swipes: The number of times the profile was swiped.we carry out a daily random allocation of 10 swipes in the profiles, both in the control and treatment groups. This measure serves a dual purpose: first, it keeps our profiles actively participating in the app, and second, it facilitates interaction with other profiles, increasing the visibility of our profiles to other users. 
- Likes: The number of likes received by the profile.
- Matches: The number of matches made by the profile.
- Comments: The number of comments received on the profile. The number of comments, that responded to the prompt.
- OwnerNum: Owner variable transformed into an integer variable
- ProfileNum: Profile Name variable transformed into an integer
- CityNum: City variable transformed into an integer
- Day: Date variable transformed into an integer based on the day number in the experiment. Starting from one.

Records with missing values were omitted from the data.

```{r read hinge data}
d<- na.omit(fread("/home/rstudio/w241_team_Project/Final_project/data/W241_Hinge_Data_v2.csv"))
setnames(d, "Profile Name", "Profile_Name")
setnames(d, "Control vs Treatment", "Treat")
d[, Treat_binary := as.integer(Treat == "Treatment")]
head(d)
```
# Randomization Check
A randomization check was performed to evaluate whether our treatment and control groups make up representative samples. To perform this check two regression models were developed. The first model: null_mod is the simplest and captures the intercept. The second model: full_mod is more complex and includes profile characteristic variables such as: Who created the profile (Owner), The profile's name (Profile), The location -- San Francisco or New York -- the profile is active (City), The day the sample was collected (Day), and the number of swipes taken on the profile (Swipes).

```{r}
null_mod <- d[ , lm(Treat_binary ~ 1)]

full_mod <- d[ , lm(Treat_binary ~ 1 + OwnerNum + ProfileNum + City + ExpDay + Swipes)]
```

The first simple model illustrates a 0.502 intercept to support the assumption that both treatment and control groups make up representative samples. However, the more complex model with five covariates captures a small pattern. The City variable has a statistically significant correlation with treatment outcomes. This suggests that different profile locations (San Francisco or New York) contribute to sample differences between the treatment group and the control group.

```{r warning=FALSE}
stargazer(null_mod, full_mod, 
          type = "text",
         covariate.labels = c("Owner", "Profile", "City - San Francisco", "Day", "Swipes", "Intercept")
          )
```
However, while the City variable is statistical significant the impact seems impractically significant at 0.131. 
To further illustrate the minimal impact the City variable has on treatment assignment, we've run an F-test between our two models (null mod, full mod). As suspected, while City location is statistically significant, the difference does not result in material differences in model performance. While variance is higher with our simple model, it still generates the same outcomes as the complex model for 97% of samples.

```{r}
anova_mod <- anova(full_mod, null_mod, test = 'F')
anova_mod
```
# Experimentation

In this section, we delve deeper into the analysis of our experiment, aiming to elucidate the impact of incorporating a humorous personality into dating app profiles while accounting for various control variables. Our primary objective remains consistent: to assess the effect of the treatment variable, denoting the presence of a highly humorous and intriguing personality description within the profile, on user engagement metrics, specifically, the number of likes and matches.

## Simple Causal Experiment
```{r warning=FALSE}
simple_match_model <- d[ , lm(Treat_binary ~ Matches)]
simple_like_model <- d[ , lm(Treat_binary ~ Likes)]


robust_match_model <- coeftest(simple_match_model, 
                               vcov = vcovHC(simple_match_model, type = "HC3"))
robust_like_model <- coeftest(simple_like_model, 
                              vcov = vcovHC(simple_like_model, type = "HC3"))

stargazer(robust_match_model, robust_like_model, 
          type = "text", header=FALSE)
```
### Model 1: Humor ~ Matches

Model 1 examines the impact of our treatment variable on the number of matches. For each additional match, the likelihood of being in the treatment group (having a humorous personality description) increases by approximately 0.076 units. The coefficient for matches is highly statistically significant (p < 0.01), indicating a strong and robust relationship between the number of matches and being in the treatment group. 

### Model 2: Humor ~ Likes

Model 2 examines the impact of our treatment variable on the number of likes. For each additional like received, there is a marginal increase (0.017 units) in the likelihood of being in the treatment group (having a humorous personality description).
The coefficient for Likes is statistically significant at the 10% level (p < 0.1), indicating a weaker relationship between the number of likes and being in the treatment group compared to Model 1.

In summary, Model 1 demonstrates a robust and highly significant relationship between the number of matches and being in the treatment group, with a substantial increase in the likelihood of having a humorous personality description for each additional match. Model 2, while statistically significant, indicates a weaker relationship between the number of likes and being in the treatment group, with a smaller increase in likelihood per additional like compared to matches. These results emphasize the importance of matches in influencing the likelihood of a humorous personality description in dating profiles.

## Causal Experiments with More Controls
Building upon the foundation laid in the earlier section, where we examined the simple relationships between the treatment variable and our outcome variables, Likes, Matches, and Comments, we recognize the need to consider a broader context. While those initial analyses provided valuable insights into the direct effects of the humorous personality description, they may not account for other factors that could influence user engagement on dating apps.

To address this, we embark on a more comprehensive analytical journey by introducing additional control variables into our regression models. By doing so, we aim to control for potential confounding variables that might otherwise obscure the true impact of the treatment variable. These control variables encompass demographic and contextual factors, allowing us to explore how the humorous personality description affects user engagement while holding other relevant factors constant.

```{r warning=FALSE}
controls_match_model <- d[ , lm(Treat_binary ~ Matches + Swipes+ factor(Owner) + 
                                  factor(City) + factor(ExpDay))]
controls_like_model <- d[ , lm(Treat_binary ~ Likes + Swipes+ factor(Owner) + 
                                 factor(City) + factor(ExpDay))]

robust_controls_match_model <- coeftest(controls_match_model, 
                              vcov = vcovHC(controls_match_model, type = "HC3"))
robust_controls_like_model <- coeftest(controls_like_model, 
                              vcov = vcovHC(controls_like_model, type = "HC3"))

stargazer(robust_controls_match_model, robust_controls_like_model, 
          omit = "factor(ExpDay)", type = "text", header=FALSE)
```

### Model 1: Humor ~ Matches + Controls
Model 1 examines the impact of our treatment variable on the number of matches to include additional control variables (profile owner, profile location, and day of experiment).
The coefficient for Matches is 0.095, and it is highly statistically significant (p < 0.01). This indicates that for each additional match, the likelihood of being in the treatment group (having a humorous personality description) increases significantly by approximately 0.094 units, after controlling for other variables.
The coefficient for Swipes is not statistically significant (p > 0.1), suggesting that the number of swipes does not have a significant effect on being in the treatment group.
The coefficients for the different levels of the Owner variable (e.g., Erin Smith, KT, Luka, Quazi) represent how each owner's profile relates to being in the treatment group compared to a reference category. None of these coefficients are statistically significant at conventional levels (p > 0.1), indicating that the owner's identity does not have a significant effect on being in the treatment group.
The coefficient for the San Francisco city dummy variable is 0.127, and it is marginally statistically significant at the 10% level (p < 0.1). This suggests that being located in San Francisco may have a slight positive impact on being in the treatment group, although the significance level is not very strong.
The coefficients for the different days (ExpDay 2 to 45) represent how each day of the experiment relates to being in the treatment group compared to a reference category. Most of these coefficients are not statistically significant (p > 0.1), suggesting that specific days do not have a significant effect on being in the treatment group.


### Model 2: Humor ~ Likes + Controls
Model 2 examines the impact of our treatment variable on the number of likes to include additional control variables (profile owner, profile location, and day of experiment).
The coefficient for Likes is 0.033, and it is statistically significant at the 5% level (p < 0.05). This indicates that for each additional like received, there is a statistically significant increase of approximately 0.033 units in the likelihood of being in the treatment group (having a humorous personality description), after controlling for other variables.
Similar to Model 1, the coefficients for swipes and the different levels of the Owner variable do not reach statistical significance (p > 0.1), suggesting that both swipes and the owner's identity does not significantly affect being in the treatment group.
The coefficient for the San Francisco city dummy variable is 0.140, and it is statistically significant at the 5% level (p < 0.05). This indicates that being located in San Francisco has a statistically significant positive impact on being in the treatment group.

In both models, Matches (in Model 1) and Likes (in Model 2) have a statistically significant impact on being in the treatment group, with Matches being highly significant and Likes being significant at the 5% level. This suggests that both the number of matches and the number of likes influence the likelihood of having a humorous personality description in dating app profiles.

Regarding the control variables Owner and City, none of the specific owner identities significantly affect being in the treatment group in either model. However, the city variable shows some significance, with being located in San Francisco positively associated with being in the treatment group.

## Experimentation Results
Overall, these results confirm that having a humorous personality description significantly influences user engagement on dating apps, particularly through an increase in both matches and likes. The control variables in these models do not exhibit significant effects on being in the treatment group, reinforcing the importance of personality traits expressed through text in shaping user interactions and experiences on dating apps.
